{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "name": "Sentiment Analysis with RNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kamranjaved/Workshop-on-AI-and-Hand-on-training/blob/main/Sentiment_Analysis_with_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvSSt3Hvv8tY"
      },
      "source": [
        "## Urdu Tweets Sentiment Analysis with RNN\n",
        "\n",
        "We will use Recurrent Neural Networks, and in particular LSTMs, to perform sentiment analysis in Keras.  Conveniently, Keras has a built-in IMDb movie reviews dataset that we can use."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LEj6grutdTv-",
        "outputId": "6e557335-bbf4-446e-bc53-a6a5feef1f92"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmEbkg2e9rW9"
      },
      "source": [
        "# !pip install urduhack\r\n",
        "import urduhack"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZNRYA5W9-7P"
      },
      "source": [
        ""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0vNEzWl9-yX"
      },
      "source": [
        ""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UzjiHz-XRgY"
      },
      "source": [
        "import pandas as pd\r\n",
        "df=pd.read_csv('/content/drive/My Drive/urdu2.csv')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "FAODTvNchqfl",
        "outputId": "0d63e097-676c-4402-8aed-afaffd44c02e"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweet</th>\n",
              "      <th>Class</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>میں نے ایٹم بم بنایا ھے ۔۔۔۔او بھائی ایٹم بمب ...</td>\n",
              "      <td>P</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>چندے سے انقلاب اور عمران خان وزیر اعظم نہیں بن...</td>\n",
              "      <td>N</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ٹویٹر کا خیال کیسے آیا ؟</td>\n",
              "      <td>O</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>سرچ انجن گوگل کے نائب صدر نے فضا میں ، 130,000...</td>\n",
              "      <td>P</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ابھی تک اسکی لہریں کبھی کبھی آ جاتی ہیں یار :أْ</td>\n",
              "      <td>P</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               Tweet Class  Label\n",
              "0  میں نے ایٹم بم بنایا ھے ۔۔۔۔او بھائی ایٹم بمب ...     P      1\n",
              "1  چندے سے انقلاب اور عمران خان وزیر اعظم نہیں بن...     N      0\n",
              "2                           ٹویٹر کا خیال کیسے آیا ؟     O      1\n",
              "3  سرچ انجن گوگل کے نائب صدر نے فضا میں ، 130,000...     P      1\n",
              "4    ابھی تک اسکی لہریں کبھی کبھی آ جاتی ہیں یار :أْ     P      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "3TWz62wY-mhH",
        "outputId": "d7e175be-8b8e-4bd9-b927-59cfc3634093"
      },
      "source": [
        "df.Tweet[0]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'میں نے ایٹم بم بنایا ھے ۔۔۔۔او بھائی ایٹم بمب کوٹ لکھپت والی اتفاق فیکٹری میں نہیں بنتا۔ایٹم بم کہوٹہ کی ایٹمی۔۔۔ '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 494
        },
        "id": "tQNEzmulm52l",
        "outputId": "a3988d16-27c9-4d53-f1d8-6a7a997296a4"
      },
      "source": [
        "\r\n",
        "df=pd.read_csv('/content/drive/My Drive/urdu2.csv')\r\n",
        "import urduhack\r\n",
        "\r\n",
        "# Downloading models\r\n",
        "urduhack.download()\r\n",
        "\r\n",
        "\r\n",
        "for ctr in range(len(df.Tweet)):\r\n",
        "  split_text = []\r\n",
        "  sentence = df.Tweet[ctr]\r\n",
        "  for word in sentence.split():\r\n",
        "    split_text.append(word)\r\n",
        "  df.Tweet[ctr] = split_text\r\n",
        "df\r\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweet</th>\n",
              "      <th>Class</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[میں, نے, ایٹم, بم, بنایا, ھے, ۔۔۔۔او, بھائی, ...</td>\n",
              "      <td>P</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[چندے, سے, انقلاب, اور, عمران, خان, وزیر, اعظم...</td>\n",
              "      <td>N</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[ٹویٹر, کا, خیال, کیسے, آیا, ؟]</td>\n",
              "      <td>O</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[سرچ, انجن, گوگل, کے, نائب, صدر, نے, فضا, میں,...</td>\n",
              "      <td>P</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[ابھی, تک, اسکی, لہریں, کبھی, کبھی, آ, جاتی, ہ...</td>\n",
              "      <td>P</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>[اُس, آدمی, نے, اِس, سالار, کو, کافی, معقول, ٹ...</td>\n",
              "      <td>P</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>[چچا, غالب, کی, روح, سے, معذرت, کے, ساتھہم, نے...</td>\n",
              "      <td>P</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>[واہ, جناب, واہ!, اچھی, رہی۔, جناب, خود, کو, ف...</td>\n",
              "      <td>P</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>[اسلام, آباد, :پی, اے, ٹی, کا, دھرنا, ختم،, صف...</td>\n",
              "      <td>P</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>[دنیا, نے, کس, کا, راہ, وفا, میں, دیا, ہے, سات...</td>\n",
              "      <td>P</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 Tweet Class  Label\n",
              "0    [میں, نے, ایٹم, بم, بنایا, ھے, ۔۔۔۔او, بھائی, ...     P      1\n",
              "1    [چندے, سے, انقلاب, اور, عمران, خان, وزیر, اعظم...     N      0\n",
              "2                      [ٹویٹر, کا, خیال, کیسے, آیا, ؟]     O      1\n",
              "3    [سرچ, انجن, گوگل, کے, نائب, صدر, نے, فضا, میں,...     P      1\n",
              "4    [ابھی, تک, اسکی, لہریں, کبھی, کبھی, آ, جاتی, ہ...     P      1\n",
              "..                                                 ...   ...    ...\n",
              "995  [اُس, آدمی, نے, اِس, سالار, کو, کافی, معقول, ٹ...     P      1\n",
              "996  [چچا, غالب, کی, روح, سے, معذرت, کے, ساتھہم, نے...     P      1\n",
              "997  [واہ, جناب, واہ!, اچھی, رہی۔, جناب, خود, کو, ف...     P      1\n",
              "998  [اسلام, آباد, :پی, اے, ٹی, کا, دھرنا, ختم،, صف...     P      1\n",
              "999  [دنیا, نے, کس, کا, راہ, وفا, میں, دیا, ہے, سات...     P      1\n",
              "\n",
              "[1000 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFp4vDq1nKdK",
        "outputId": "a06a84f5-1096-4322-b24b-a8210bb03edf"
      },
      "source": [
        "len(df.Tweet)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DNlBZvEtv6l"
      },
      "source": [
        "\r\n",
        "import itertools\r\n",
        "all_tokens = itertools.chain.from_iterable(df.Tweet)\r\n",
        "Vocabulary = {token: idx for idx, token in enumerate(set(all_tokens))}"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4I8R_T6wtvuM",
        "outputId": "63f64c05-4fe7-4244-d47a-0bc3182b29ee"
      },
      "source": [
        "Vocabulary['حکم']"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3462"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xSmmEsn-8LQh",
        "outputId": "87b409b7-9876-4289-e90a-4d5fe43fbe99"
      },
      "source": [
        "len(Vocabulary)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5701"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 494
        },
        "id": "yZX6TZs8-GZy",
        "outputId": "5713455c-f4e1-4450-c232-33553036ea3a"
      },
      "source": [
        "df=pd.read_csv('/content/drive/My Drive/urdu2.csv')\r\n",
        "import urduhack\r\n",
        "# Downloading models\r\n",
        "urduhack.download()\r\n",
        "\r\n",
        "\r\n",
        "for ctr in range(len(df.Tweet)):\r\n",
        "  split_ids = []\r\n",
        "  sentence = df.Tweet[ctr]\r\n",
        "  for word in sentence.split():\r\n",
        "     split_ids.append(Vocabulary[word])   \r\n",
        "\r\n",
        "\r\n",
        "  df.Tweet[ctr] = split_ids\r\n",
        "\r\n",
        "df"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweet</th>\n",
              "      <th>Class</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[117, 4565, 4992, 5668, 1703, 5232, 1579, 1664...</td>\n",
              "      <td>P</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[4184, 2129, 2821, 2213, 2332, 5377, 3753, 752...</td>\n",
              "      <td>N</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[560, 4142, 175, 3543, 5540, 4076]</td>\n",
              "      <td>O</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[188, 668, 1555, 2476, 4463, 2773, 4565, 763, ...</td>\n",
              "      <td>P</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[1609, 1662, 3149, 4045, 3266, 3266, 4577, 258...</td>\n",
              "      <td>P</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>[5518, 4476, 4565, 3814, 1148, 254, 3396, 717,...</td>\n",
              "      <td>P</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>[5077, 4116, 2643, 1690, 2129, 4563, 2476, 244...</td>\n",
              "      <td>P</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>[67, 4030, 3208, 1790, 1526, 4030, 1893, 254, ...</td>\n",
              "      <td>P</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>[5129, 3809, 89, 5062, 5241, 4142, 3289, 1041,...</td>\n",
              "      <td>P</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>[624, 4565, 2374, 4142, 4795, 5015, 117, 1080,...</td>\n",
              "      <td>P</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 Tweet Class  Label\n",
              "0    [117, 4565, 4992, 5668, 1703, 5232, 1579, 1664...     P      1\n",
              "1    [4184, 2129, 2821, 2213, 2332, 5377, 3753, 752...     N      0\n",
              "2                   [560, 4142, 175, 3543, 5540, 4076]     O      1\n",
              "3    [188, 668, 1555, 2476, 4463, 2773, 4565, 763, ...     P      1\n",
              "4    [1609, 1662, 3149, 4045, 3266, 3266, 4577, 258...     P      1\n",
              "..                                                 ...   ...    ...\n",
              "995  [5518, 4476, 4565, 3814, 1148, 254, 3396, 717,...     P      1\n",
              "996  [5077, 4116, 2643, 1690, 2129, 4563, 2476, 244...     P      1\n",
              "997  [67, 4030, 3208, 1790, 1526, 4030, 1893, 254, ...     P      1\n",
              "998  [5129, 3809, 89, 5062, 5241, 4142, 3289, 1041,...     P      1\n",
              "999  [624, 4565, 2374, 4142, 4795, 5015, 117, 1080,...     P      1\n",
              "\n",
              "[1000 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Tx6avuYl-fy"
      },
      "source": [
        "# import numpy as np\r\n",
        "Lable = df.Lable\r\n",
        "Tweet = df.Tweet\r\n",
        "# Data = [Lable, Tweet]\r\n",
        "# print(np.shape(Data))\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVx_ippQAmEo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L570RWGcy5-Z"
      },
      "source": [
        "#Import Module\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "\r\n",
        "train_X_urdu, test_X_urdu, train_y_urdu, test_y_urdu = train_test_split( df.Tweet, df.Label, \r\n",
        "                                                    train_size=0.7,\r\n",
        "                                                    test_size=0.3\r\n",
        "                                                    )"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_761bPvklwll"
      },
      "source": [
        "train_X_urdu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKb8lGx5Z3zO"
      },
      "source": [
        "y_train = train_y_urdu\r\n",
        "y_test =  test_y_urdu\r\n",
        "X_train = train_X_urdu\r\n",
        "X_test =  test_X_urdu"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wks9FfVkI363"
      },
      "source": [
        "vocabulary_size = 6000"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOGSZLRcaaWI",
        "outputId": "182bab14-db76-4897-eac3-d207362d2ec7"
      },
      "source": [
        "print('Loaded dataset with {} training samples, {} test samples'.format(len(X_train), len(X_test)))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded dataset with 700 training samples, 300 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "accoqoQ4ak9M"
      },
      "source": [
        "len(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GwDzEJFSCUbg",
        "outputId": "2eaee95e-a43a-4778-d80e-27cd82d9ce70"
      },
      "source": [
        "# print(len(y_test))\r\n",
        "# print(len(max((X_train))))\r\n",
        "print('Maximum Tweet length: {}'.format( max( len(max(X_train)) , len(max(X_test)))))\r\n",
        "print('Minimum Tweet length: {}'.format( min( len(min(X_train)) , len(min(X_test)))))\r\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Maximum Tweet length: 23\n",
            "Minimum Tweet length: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_Eu6gJ4v8tm"
      },
      "source": [
        "\r\n",
        "from keras.datasets import imdb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKsProz4v8tn"
      },
      "source": [
        "vocabulary_size = 5000\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words = vocabulary_size)\n",
        "print('Loaded dataset with {} training samples, {} test samples'.format(len(X_train), len(X_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQefJdGfv8to"
      },
      "source": [
        " Inspect a sample review and its label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kg5dJzpgv8tp"
      },
      "source": [
        "Map word IDs back to words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcTlk0mWv8tq"
      },
      "source": [
        "word2id = imdb.get_word_index()\n",
        "id2word = {i: word for word, i in word2id.items()}\n",
        "print('---review with words---')\n",
        "print([id2word.get(i, ' ') for i in X_train[6]])\n",
        "print('---label---')\n",
        "print(y_train[6])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwAGSxL-v8ts"
      },
      "source": [
        "Maximum review length and minimum review length"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGFI61sJv8ts"
      },
      "source": [
        "print('Maximum review length: {}'.format(\n",
        "len(max((X_train + X_test), key=len))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rOoEPyKv8tt"
      },
      "source": [
        "max_words = max( len(max((X_train))) , len(max((X_test))))\n",
        "print('Minimum Tweet length: {}'.format(\n",
        "max( len(max((X_train))) , len(max((X_test))))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCXv7aj4v8tt"
      },
      "source": [
        "### Pad sequences\n",
        "\n",
        "In order to feed this data into our RNN, all input documents must have the same length. We will limit the maximum review length to max_words by truncating longer reviews and padding shorter reviews with a null value (0). We can accomplish this using the pad_sequences() function in Keras. For now, set max_words to 500."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtYnHnQLHzh3"
      },
      "source": [
        "type(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVhr9_Z6Qgw4"
      },
      "source": [
        "max_words = 500"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4mUlGrkv8tu"
      },
      "source": [
        "from keras.preprocessing import sequence\n",
        "\n",
        "max_words = 500\n",
        "X_train = sequence.pad_sequences(X_train, maxlen=max_words)\n",
        "                                #  ,  dtype='float', padding='pre',  truncating='pre', value=0.0)\n",
        "# , dtype='object')\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=max_words)\n",
        "                                # ,  dtype='float', padding='pre',  truncating='pre', value=0.0)\n",
        "                                # , dtype='object')"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_oyoyHVdv8tu"
      },
      "source": [
        "### TODO: Design an RNN model for sentiment analysis\n",
        "\n",
        "Build our model architecture in the code cell below. We have imported some layers from Keras that you might need but feel free to use any other layers / transformations you like.\n",
        "\n",
        "Remember that our input is a sequence of words (technically, integer word IDs) of maximum length = max_words, and our output is a binary sentiment label (0 or 1)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EFypHUbxv8tv",
        "outputId": "5ac665e3-7283-4670-9f47-5bc978df54e0"
      },
      "source": [
        "from keras import Sequential\n",
        "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "\n",
        "embedding_size=32\n",
        "model=Sequential()\n",
        "model.add(Embedding(vocabulary_size, embedding_size, input_length=max_words))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 500, 32)           192000    \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 100)               53200     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 245,301\n",
            "Trainable params: 245,301\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ga4f3Zwiv8tv"
      },
      "source": [
        "To summarize, our model is a simple RNN model with 1 embedding, 1 LSTM and 1 dense layers. 213,301 parameters in total need to be trained."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wWb0-Ehfv8tv"
      },
      "source": [
        "### Train and evaluate our model\n",
        "\n",
        "We first need to compile our model by specifying the loss function and optimizer we want to use while training, as well as any evaluation metrics we'd like to measure. Specify the approprate parameters, including at least one metric 'accuracy'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLfdWJOPv8tw"
      },
      "source": [
        "model.compile(loss='binary_crossentropy', \n",
        "             optimizer='adam', \n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7n8gUyxlv8tw"
      },
      "source": [
        "Once compiled, we can kick off the training process. There are two important training parameters that we have to specify - batch size and number of training epochs, which together with our model architecture determine the total training time.\n",
        "\n",
        "Training may take a while, so grab a cup of coffee, or better, go for a run!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uaia2e_sv8tw",
        "outputId": "da0ee42a-5b2b-43f3-c192-24768761c9a3"
      },
      "source": [
        "batch_size = 10\n",
        "num_epochs = 5\n",
        "\n",
        "X_valid, y_valid = X_train[:batch_size], y_train[:batch_size]\n",
        "X_train2, y_train2 = X_train[batch_size:], y_train[batch_size:]\n",
        "\n",
        "model.fit(X_train, y_train, validation_data=(X_valid, y_valid), batch_size=batch_size, epochs=num_epochs)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "70/70 [==============================] - 19s 253ms/step - loss: 0.6936 - accuracy: 0.5428 - val_loss: 0.6816 - val_accuracy: 0.8000\n",
            "Epoch 2/5\n",
            "70/70 [==============================] - 17s 247ms/step - loss: 0.6872 - accuracy: 0.7134 - val_loss: 0.5894 - val_accuracy: 0.9000\n",
            "Epoch 3/5\n",
            "70/70 [==============================] - 17s 247ms/step - loss: 0.5453 - accuracy: 0.8758 - val_loss: 0.3762 - val_accuracy: 0.9000\n",
            "Epoch 4/5\n",
            "70/70 [==============================] - 17s 247ms/step - loss: 0.3122 - accuracy: 0.9573 - val_loss: 0.1807 - val_accuracy: 0.9000\n",
            "Epoch 5/5\n",
            "70/70 [==============================] - 17s 246ms/step - loss: 0.1050 - accuracy: 0.9916 - val_loss: 0.1561 - val_accuracy: 0.9000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fdab8078850>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqXQOf5fF1O2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8aOb-WYFv8tx"
      },
      "source": [
        "scores[1] will correspond to accuracy if we pass metrics=['accuracy']"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FucT5BlZv8tx",
        "outputId": "974f9263-e9d0-423a-8f48-6c774912b5e9"
      },
      "source": [
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test accuracy:', scores[0])"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy: 0.8954396843910217\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}